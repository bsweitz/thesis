\chapter{Effective Derivations}\label{cha:effective_derivations}
In this section we prove that several sets of constraints corresponding to natural combinatorial optimization problems are effective.
We first note that the very simplest sets of constraints are effective.
\begin{lemma}\label{lem:grobnereffective}
Let $\cP$ be a Gr\"obner basis. Then $\cP$ is $1$-effective in the PC proof system.
\end{lemma}
\begin{proof}
Recall that if $\cP$ is a Gr\"obner basis, then multivariate polynomial division by $\cP$ is well-defined, and in fact there is a unique 
remainder. Let $r \in \gen{\cP}$ be of degree $d$, and consider the division of $r$ by $\cP$. Because $r \in \gen{\cP}$, this division must have
remainder zero. If we enumerate the polynomials that are produced in the course of this division $r = r_0, r_1, \dots, r_N = 0$, then 
$r_i = r_{i+1} + q_{i+1}p_{i+1}$, where $p_{i+1} \in \cP$ and $\deg r_{i+1} \leq \deg r_i$. Combining all these sums into one, we get
$r = \sum_i q_i p_i$, which is a derivation of degree $d$. 
\end{proof}
\prettyref{lem:grobnereffective} is trivial to prove, but there are several important combinatorial optimization problems that fall 
under its umbrella.
\begin{corollary}
\textsc{CSP} is $1$-effective.
\end{corollary}
\begin{proof}
Recall that \textsc{CSP} corresponds to the set of constraints $\cP = \{x_i^2 - x_i | i \in [n]\}$. We prove this is a Gr\"obner basis. 
Let $p \in \gen{\cP}$. If $p$ is not multilinear, we can divide $p$ by elements of $\cP$ until we have a multilinear remainder $r$. Because 
$p \in \gen{\cP}$ and each element of $\cP$ is zero on the hypercube $\{0, 1\}^n$, $r$ must also be zero on the hypercube. But the multilinear
polynomials form a basis for functions on the hypercube, so if $r$ is a multilinear polynomial which is zero, then it must be the zero polynomial. 
\end{proof}
\begin{corollary}
\textsc{CLIQUE} is $1$-effective.
\end{corollary}
\begin{proof}
Recall that \textsc{CLIQUE}$(V,E)$ corresponds to the set of constraints $\cP = \{x_i^2 - x_i | i \in [|V|]\} \cup \{ x_ix_j | (i,j) \notin E\}$. 
We prove this is a Gr\"obner basis. Let $p \in \gen{\cP}$. Just as above, if $p$ is not multilinear, we can divide it until we have a multilinear
remainder $r_1$. Now by dividing $r_1$ by the polynomials in the second part of $\cP$, we can remove all monomials containing $x_ix_j$ where $(i,j) \notin E$
to get $r_2$. Thus $r_2$ contains only monomials which are cliques of varying sizes in the graph $(V,E)$. Let $C$ be the smallest clique with a
nonzero coefficient $\alpha_C$ in $r_2$. Let $\chi_C$ be the characteristic vector of $C$, i.e. $(\chi_C)_i = 1$ if $i \in C$, and $(\chi_C)_i = 0$ otherwise.
Then $r_2(\chi_C) = \alpha_C$. But $p(\chi_C) = 0$ for every $p \in \cP$, and $r_2 \in \gen{\cP}$. Thus $\alpha_C = 0$, a contradiction, and so $r_2$ is the 
zero polynomial.
\end{proof}

However, not every problem falls so neatly into this classification. There are many natural problems whose solution spaces have a small set of generating
polynomials which are not Gr\"obner bases, and indeed their Gr\"obner bases can be exponentially large and exceedingly difficult to compute. Despite this,
these problems can still admit effective derivations, as we prove here.

\section{More Complicated Solution Spaces}
In this section, we will prove that the \textsc{Matching} and \textsc{Balanced-CSP} problems have effective solution spaces. Both of the solution spaces have
two properties that are important for our proofs. Firstly, they are very symmetric: one can permute the vertices of a matching however one wishes and still have a matching. Similarly, permuting the names of variables does not change the balance of an assignment. 
Secondly, they are inductive: deleting an edge from a matching results in a matching on a smaller graph. 
Similarly, removing a pair of variables with different values gives you an assignment, although it could be differently balanced.
The proofs described in this section should be adaptable to any problem whose solution space has similar properties.

Our proofs are by induction, and they proceed in two steps. 
First, we show that any perfectly symmetric polynomial $p$ of degree $d$ can be derived from a constant polynomial in degree $d$.
This step is easy and straightforward. 
The second, and much harder, step is to show that given a $p$ which is constant on $V(\cP)$ and any permutation $\sigma$, the polynomial $p - \sigma p$ can be derived in low degree. 
This second step is accomplished with an inductive argument that shows how to use $\cP$ to strip off two of the variables of the solutions. 
The group action that determines the definition of "`perfectly symmetric"' and $\sigma p$ has not been specified yet, but it will be the natural permutation of the underlying solution space.

%Intuitively speaking, this means that their solution spaces are simple and easily explained. Any polynomial fact over the solution space
%can be proven using a proof of only roughly the same complexity of the fact.  
\subsection{Effective Derivations for \textsc{Matching}}
Fix an integer $n$, and recall that the matching constraints are polynomials in $\R^{\binom{n}{2}}$ (we abuse notation and use $x_{ij}$ and $x_{ji}$ equivalently):
\[\cP = \{x_{ij}^2 - x_{ij} | i,j \in [n]\} \cup \{\sum_i x_{ij} - 1 | j \in [n]\} \cup \{x_{ij}x_{ik} | i,j,k \in [n]\}.\]
For an element $\sigma$ of the symmetric group $\cS_n$, we define the action of $\sigma$ on a variable by $\sigma x_{ij} = x_{\sigma(i)\sigma(j)}$.
We define the action of $\sigma$ on a monomial by extending this action multiplicatively, and the action of $\sigma$ on a full polynomial by extending linearly.
Note that $\cP$ is fixed by the action of every $\sigma$, as are its solutions $V(\cP)$ corresponding to the matchings of $K_n$. 
Thus for any $p \in \cP$, we also have $\sigma p \in \cP$. For a partial matching $M$, i.e. a set of disjoint pairs from $[n]$, define $x_M = \prod_e \in M x_e$.
First, we note an easy lemma on the structure of polynomials in $\gen{\cP}$:
\begin{lemma}\label{lem:monomials}
  Let $p$ be any polynomial. Then there is a multilinear polynomial $q$ such that every monomial of $q$ is a partial matching monomial, and $p-q$ has a derivation from $\cP$ of degree $\deg p$.
\end{lemma}
\begin{proof}
It suffices to prove the lemma when \(p\) is a monomial. Let
\(p = \prod_{e \in A} x_{e}^{k_{e}}\)
for a set \(A\) of edges with multiplicities \(k_{e} \geq 1\).
From the constraint \(x_{e}^{2} - x_e\), it follows that
$\prod_{e \in A} x_e^{k_e} - \prod_{e \in A} x_e$ has a derivation from $\cP$ in degree $\deg p$.
Now if $A$ is a partial matching we are done, otherwise there exist edges $f,g \in A$ which are not disjoint.
But then $x_fx_g \in \cP$, and so $\prod_{e \in A} x_e$ has a derivation from $\cP$ in degree $|A|$, which implies the statement.
\end{proof}
\prettyref{lem:monomials} will often simplify our analysis for the next section, where we prove that symmetric polynomials have effective derivations.

\subsubsection{Effective Derivations for Symmetric Polynomials}

We will prove the following lemma: 
\begin{lemma}
  \label{lem:constant}
  Let $p$ be a polynomial in $\R^{\binom{n}{2}}$.
	Then there is a constant $c_p$ such that $\sum_{\sigma \in \cS_n} \sigma p - c_p$ has a derivation from $\cP$ in degree at most $\deg p$. 
\end{lemma}
To do so, it will be useful to first prove a few lemmas on how we can simplify the structure of $p$. 

Any partial matching monomial may be extended as a sum over partial matching monomials containing that partial matching using the constraint $\sum_j x_{ij} - 1 \in \cP$. The first lemma here shows how to extend by a single edge, and the second iteratively applies this process to extend by multiple edges.
\begin{lemma}
  \label{lem:matching+a}
  For any partial matching \(M\) on \(2d\) vertices
  and a vertex \(u\) not covered by \(M\),
  \begin{equation}
    \label{eq:matching+a}
    x_{M}
    \cong
    \sum_{\substack{M_{1} = M \cup \{u,v\}: \\
        v \in [n] \setminus (M \cup \{u\})}}
    x_{M_{1}}
    ,
  \end{equation}
	and the derivation can be done in degree $d+1$.
\end{lemma}
\begin{proof}
We use the constraints \(\sum_{v} x_{uv} - 1\)
to add variables corresponding to edges at \(u\),
and then use \(x_{uv} x_{uw}\) to remove monomials
not corresponding to a partial matching:
\begin{equation*}
  x_{M}
  \cong
  x_{M} \sum_{v \in K_n} x_{uv}
  \cong
  \sum_{\substack{M_{1} = M \cup \{u,v\}: \\
      v \in K_{n} \setminus (M \cup \{u\})}}
  x_{M_{1}}
  .
\end{equation*}
It is easy to see that these derivations are done in degree $d+1$.
\end{proof}
\begin{lemma}
  \label{lem:partial-matching}
  For any partial matching \(M\) of \(2d\) vertices
  and \(d \leq k \leq n/2\),
  we have
  \begin{equation}
    \label{eq:partial-matching}
    x_{M} \cong
    \frac{1}{\binom{n/2 - d}{k - d}}
    \sum_{\substack{M' \supset M \\ \size{M'} = k}} x_{M'}
  \end{equation}
\end{lemma}
\begin{proof}
We use induction on \(k - d\).
The start of the induction is with \(k = d\),
when the sides of \prettyref{eq:partial-matching}
are actually equal. If \(k > d\), let \(u\) be a fixed vertex not covered by \(M\).
Applying \prettyref{lem:matching+a} to \(M\) and \(u\)
followed by the inductive hypothesis gives:
\begin{equation*}
	\begin{split}
    x_{M}
    &\cong
    \sum_{\substack{M_{1} = M \cup \{u,v\}: \\
        v \in K_{n} \setminus (M \cup \{u\})}}
    x_{M_{1}} \\
    &\cong
    \frac{1}{\binom{n/2 - d - 1}{k - d - 1}}
    \sum_{\substack{
        M' \supset M_{1} \\ \size{M'} = k \\
        M_{1} = M \cup \{u,v\}: \\
        v \in K_{n} \setminus (M \cup \{u\})}}
    x_{M'}
    \end{split}
    .
\end{equation*}
Averaging over all vertices \(u\) not covered by \(M\),
we obtain:
\begin{equation*}
  \begin{split}
  x_{M}
  &\cong
  \frac{1}{n - 2 d}
  \frac{1}{\binom{n/2 - d - 1}{k - d - 1}}
  \sum_{\substack{
      M' \supset M_{1} \\ \size{M'} = k \\
      M_{1} = M \cup \{u,v\}: \\
      \{u, v\} \in K_{n} \setminus M}}
  x_{M'} \\
  &=
  \frac{1}{n - 2 d}
  \frac{1}{\binom{n/2 - d - 1}{k - d - 1}}
  2 (k - d)
  \sum_{\substack{
      M' \supset M \\ \size{M'} = k}}
  x_{M'} \\
  &=
  \frac{1}{\binom{n/2 - d}{k - d}}
  \sum_{\substack{M' \supset M \\ \size{M'} = k}}
  x_{M'}
  \end{split}
  .
\end{equation*}
where in the second step the factor \(2(k - d)\) accounts for the different choices of $\{u,v\}$ that can lead to extending $M$ to $M'$.
\end{proof}
For a partial matching \(M\),
let \(x_{M} \coloneqq \prod_{e \in M} x_{e}\)
denote the product of edge variables for the edges in \(M\).

Finally, we can prove the first main lemma:
\begin{proof}[Proof of \prettyref{lem:constant}]
Given \prettyref{lem:monomials},
it suffices to prove the claim for
\(p = x_{M}\) for some partial matching \(M\).
Let $\deg p = |M| = k$.
Note that $\cS_n$ acts transitively on the monomials of degree $k$, and thus $2^k k! (n-2k)!$ elements of $\cS_n$ stabilize $p$.
Thus $\sum_{\sigma \in S_n} \sigma x_M = 2^k k! (n-2k)!\sum_{M': |M'| = k} x_{M'}$.
Finally, apply \prettyref{lem:partial-matching} with $d = 0$:
\begin{equation*}
  \begin{split}
  \sum_{\sigma \in \cS_{n}} \sigma x_{M}
  &= 2^{k} k! (n-2k)! \sum_{M' \colon \size{M'} = k} x_{M'} \\
  &\cong
  2^{k} k! (n-2k)! \binom{n/2}{k}.
  \end{split}
\end{equation*}
\end{proof}
As a corollary, we get that when $p \in \gen{\cP}$, then the constant must be zero 
\begin{corollary}\label{cor:constantiszero}
If $p \in \gen{\cP}$, then $\sum_{\sigma \in \cS_n} \sigma p$ has a derivation from $\cP$ in degree $\deg p$.
\end{corollary}
\begin{proof}
Apply \prettyref{lem:constant} to obtain a constant $c_p$ such that $\sum_{\sigma \in \cS_n} \sigma p \cong c_p$. 
Now since $p \in \gen{\cP}$, $c_p \in \gen{\cP}$ as well. But the only constant polynomial in $\gen{\cP}$ is $0$.
\end{proof}

\subsubsection{Getting to a Symmetric Polynomial}
In order to apply \prettyref{lem:constant} to a general polynomial $p$, we need to show how to derive the difference polynomial $p - \sum_{\sigma \in \cS_n} \sigma p$ from $\cP$. Our proof will be by an induction on the number of vertices $n$. Because the number of vertices will be changing in this section, we will write $\cP_n$ for the matching constraints on graphs of size $n$. 
The next lemma will allow us to apply induction:
\begin{lemma}
  \label{lem:degree-increase}
  Let \(L\) be a polynomial with a degree $d$ derivation from $\cP_{n}$.
	Then $Lx_{n+1,n+2}$ has a degree $d+1$ derivation from $\cP_{n+2}$.
\end{lemma}
\begin{proof}
It suffices to prove the statement for $L \in \cP_n$. 
If $L = x_{ij}^2 - x_{ij}$ or $L = x_{ij}x_{ik}$, the claim clearly true because $L \in \cP_{n+2}$.
Then let $L = \sum_j x_{ij} - 1$, note that 
\begin{align*}
Lx_{n+1}x_{n+2} &= (\sum_{j=1}^n x_{ij} - 1)x_{n+1,n+2} \\
&= (\sum_{j=1}^{n+2} x_{ij} - 1)x_{n+1,n+2} + (-1)\cdot x_{i,n+1}x_{n+1,n+2} + (-1)\cdot x_{i,n+2}x_{n+1,n+2},
\end{align*}
and realize that all three terms contain a factor in $\cP_{n+2}$.
\end{proof}

We are now ready to prove the main theorem of this section, that the matching constraints $\cP$ admit effective derivations. 
\begin{theorem}\label{thm:matching-effective}
Let $p \in \gen{\cP_n}$, and let $d = \deg p$. Then $p$ has a derivation from $\cP_n$ in degree $2d$. 
\end{theorem}
\begin{proof}
By \prettyref{lem:monomials}, we can assume that $p$ is a multilinear polynomial whose monomials correspond to partial matchings.
As promised, our proof is by induction on $n$. Consider the base case of $n = 2$. 
Then $V(\cP_2) = \{1\}$ and either $p$ is a constant or linear polynomial.
The only such polynomials that are zero on $V(\cP_2)$ are $0$ and scalar multiples of $x_{12} - 1$. 
The former case has the trivial derivation, and the latter case is simply an element of $\cP_2$. 

Now assume that for any $d$, the theorem statement holds for polynomials in $\gen{\cP_{n'}}$ for any $n' < n$. 
Let $p \in \gen{\cP_n}$ be multilinear of degree $d$ whose monomials correspond to partial matchings, and let $\sigma = (u,v)$ be a transposition of two vertices.
We consider the polynomial $\Delta = p - \sigma p$. Note that $\Delta \in \gen{\cP_n}$, and any monomial which does not match either $u$ or $v$, or a monomial which contains $x_{uv}$, will not appear in $\Delta$ as it will be canceled by the subtraction.
Thus we can write
\[\Delta = \sum_{e: u \in e \text{ or } v \in e} L_e x_e,\]
with each $L_e$ having degree at most $d-1$. As foreshadowed earlier, our goal is to remove two of the variables in these matchings in order to apply induction. In order to do that, we will need each term to depend not only on either $u$ or $v$, but both. To this end, we multiply each term by the appropriate constraint $\sum_j x_{uj}$ or $\sum_j x_{vj}$ to obtain
\[\Delta \cong \sum_{u',v'} L_{u'v'} x_{uu'}x_{vv'}.\]
We can think of the RHS polynomial as being a partition over the possible different ways to match $u$ and $v$.
Furthermore, because of the constraints of type $x_{ij}x_{ik}$, we can take $L_{u'v'}$ to be independent of any of $u,u',v,v'$. 
We argue that $L_{u'v'} \in \cP_{n-4}$. We know that $\Delta(x) = 0$ for any $x \in V(\cP_n)$. Let $x \in V(\cP_n)$ such that $x_{uu'} = 1$ and $x_{vv'} = 1$. 
Then it must be that $x_{uw} = 0$ and $x_{vw} = 0$ for any other $w$, since otherwise $x \notin V(\cP_n)$.
Thus $\Delta(x) = L_{u'v'}(x)$. But $V(\cP_{n-4}) = V(\cP_n)|_{i,j \in [n-4]}$, and since $L_{u'v'}$ is independent of $u,u',v,v'$, $L(x) = L(x|_{i,j \neq u,u',v,v'})$, and so $L(x) = 0$ for each $x \in V(\cP_{n-4})$. Because $\cP_{n-4}$ is radical (TODO: EXPLAIN?), by \prettyref{thm:nullstellensatz} it must be that $L \in \gen{\cP_{n-4}}$. Now by the inductive hypothesis, $L_{u'v'}$ has a derivation from $\cP_{n-4}$ of degree at most $2d-2$. By two applications of \prettyref{lem:degree-increase}, $L_{u'v'}x_{uu'}x_{vv'}$ has a derivation from $\cP_n$ of degree at most $2d$, and thus so does $\Delta$.

Because transpositions generate the symmetric group, the above argument implies that $p - \frac{1}{n!}\sum_{\sigma \in \cS_n} \sigma p$ has a derivation from $\cP_n$ of degree at most $2d$. Combined with \prettyref{lem:constantiszero}, this is enough to prove the theorem statement. 
\end{proof}

\subsection{Effective Derivations for \textsc{Balanced-CSP}}
Fix an integer $n$, and recall that the \textsc{Balanced-CSP} constraints are polynomials in $\R^n$:
\[\cP = \left\{x_i^2 - x_i| i \in [n]\right\} \cup \left\{\sum_i x_i - c\right\}.\]
The \textsc{Bisection} constraints are the special case when $n$ is even and $c = n/2$. 
As before, we need to define the appropriate permuation action. For an element $\sigma \in \cS_n$, we define $\sigma x_i = x_{\sigma(i)}$ and extend this action multiplicatively and linearly to get an action on every polynomial. 
Once again, note that $\cP$ and $V(\cP)$ are fixed by $\cS_n$ under this action, and thus if $p \in \gen{\cP}$, then $\sigma p \in \gen{\cP}$. 
We will begin with the special case of \textsc{Bisection}, as we will encounter an obstacle for general $c$. 
Because $\cP$ contains the boolean constraints $\{x_i^2 - x_i | i \in [n]\}$, we will take $p$ to be a multilinear polynomial. 
Our proof strategy is the same two-step strategy as before. 

\subsubsection{Symmetric Polynomials are Constant}
The first step is to show that any symmetrized polynomial can be derived from a constant polynomial in low degree. It is considerably simpler in this case, as the fundamental theorem of symmetric polynomials tells us that powers of $\sum_i x_i$ generate all the symmetric polynomials. 
\begin{lemma}\label{lem:bcsp-symmetric}
Let $p$ be a multilinear polynomial in $\R^n$. Then there exists a constant $c_p$ such that $p' = \sum_{\sigma \in \cS_n} \sigma p \cong c_p$, and the derivation can be done in degree $\deg p$. 
\end{lemma}
\begin{proof}
It is sufficient to prove the lemma for monomials $x_A = \prod_{i \in A} x_i$. We will induct on the degree of the monomial $|A|$. 
If $|A| = 1$, then $p = x_i$ for some $i \in [n]$, and $p' = \sum_{\sigma \in \cS_n} \sigma x_i = (n-1)!\sum_i x_i \cong (n-1)!\cdot c$, which can clearly be performed in degree one. Now assume $|A| = k$, so that $p' = \sum_{\sigma \in \cS_n} \sigma x_A = (n-k)! \sum_{|B|=k} x_B$. Then $p'' = p' - \frac{(n-k)!}{k!}\left(\sum_i x_i - c\right)^k$ is a polynomial which, after multilinearizing by reducing by the boolean constraints, has degree at most $k-1$. Furthermore, $p''$ is clearly in $\gen{\cP}$ and is fixed by every $\sigma$. Thus by the inductive hypothesis, $p''$ has a derivation from some constant in degree $k-1$. Since $p' \cong p''$ in degree $k$, this implies the statement for $|A| = k$ and completes the proof by induction.
\end{proof}
By the same argument as \prettyref{cor:constantiszero}, we obtain the same result for \textsc{Balanced-CSP} constraints. We quickly note that \prettyref{lem:bcsp-symmetric} works regardless of the value of $c$, so we will reuse it when we consider the case of general $c$. Now we move on to the second step.

\subsubsection{Getting to Symmetric Polynomials}
Recall the second step of our strategy is to show that $p - \sigma p$ can be derived from $\cP$ in low degree. It will be easier in this case as compared to \textsc{Matching} because we do not have to increase the degree of $p - \sigma p$ in order to isolate a variable to remove and do the induction. Because of this, we will be able to show that \textsc{Bisection} is actually $1$-effective.
Since the number of vertices and the balance will be changing, we will use $\cP(n,c)$ to denote the \textsc{Balanced-CSP} constraints on $n$ vertices with balance $c$, and $\cP_n$ to denote the \textsc{Bisection} constraints on $n$ vertices.
We need a lemma to help us do the induction:
\begin{lemma}\label{lem:bcsp-induct}
Let $L$ be a polynomial with a degree $d$ derivation from $\cP(n,c)$. Then $L\cdot (x_{n+1} - x_{n+2})$ has a degree $d+1$ derivation from $\cP(n+2,c+1)$. 
\end{lemma}
\begin{proof}
It is sufficient to prove the lemma for $L \in \cP(n,c)$. If $L = x_i^2 - x_i$, then $L \in \cP(n+2,c+1)$ and so the lemma is clearly true. If $L = \sum_{i=0}^n x_i - c$, then 
\begin{align*}
L(x_{n+1} - x_{n+2}) &= \left(\sum_{i=0}^n x_i - c\right)(x_{n+1} - x_{n+2}) \\
&= \left(\sum_{i=0}^{n+2} x_i - (c+1)\right)(x_{n+1} - x_{n+2}) - (x_{n+1}^2 - x_{n+1}) - (x_{n+2}^2 - x_{n+2})
\end{align*}
and note that each of the three terms contains a factor from $\cP(n+2,c+1)$ and the degree is never more than $2$. 
\end{proof}
We are now ready to prove that the \textsc{Bisection} constraints admit effective derivations.
\begin{theorem}\label{thm:bisec-effective}
Let $p \in \gen{\cP_n}$ and $d = \deg p$. Then $p$ has a derivation from $\cP_n$ in degree $d$. 
\end{theorem}
\begin{proof}
By reducing by the boolean constraints, we can assume $p$ is a multilinear polynomial. 
We will induct on the number of vertices $n$, so first we must handle the base case of $n = 2$ (recall $n$ is even). 
The only degree zero polynomial in $\cP_2$ is the zero polynomial which has the trivial derivation. 
If $p = ax_1 + bx_2 + c$, we know $p(0,1) = p(1,0) = 0$. This implies $p$ is a multiple of $\sum_i x_i - 1$, which clearly has a derivation of degree $1$.
Finally, $x_1x_2$ has the derivation $x_1x_2 = x_1(x_1+x_2-1) + (-1)\cdot(x_1^2 - x_1)$.

Now assume the theorem statement for $\cP_{n'}$ with $n' < n$. 
Let $\sigma = (i,j)$ be a transposition between two vertices. 
We consider the polynomial $\Delta = p - \sigma p$. 
We can decompose $p = r_i x_i + r_j x_j + r_{ij} x_ix_j + q_{ij}$, where each of the polynomials $r_i$, $r_j$, $r_{ij}$, and $q_{ij}$ depend on neither $x_i$ nor $x_j$. Then $\Delta = (r_i - r_j)(x_i - x_j)$. Now since $\Delta \in \gen{\cP_n}$, we know that $\Delta(x) = 0$ for any $x \in \{0,1\}^n$ with exactly $n/2$ indices which are $1$. In particular, if we set $x_i = 1$ and $x_j = 0$, we know that $(r_i - r_j)$ must be zero if the remaining variables are set so that they have exactly $n/2 - 1$ indices which are $1$. In other words, $(r_i - r_j)$ is zero on $V(\cP_{n-2})$. Because STUFF IS RADICAL? TODO?, we have $(r_i - r_j) \in \gen{\cP_{n-2}}$, and thus by the inductive hypothesis $(r_i - r_j)$ has a derivation from $\cP_{n-2}$ in degree $d-1$. By \prettyref{lem:bcsp-induct}, $\Delta = (r_i - r_j)(x_i - x_j)$ has a derivation from $\cP_n$ in degree $d$. 

Now since the transpositions generate the entire symmetric group, we have $p \cong \frac{1}{n!} \sum_{\sigma \in \cS_n} \sigma p \cong 0$, where the last congruence is by \prettyref{lem:bcsp-symmetric}. Thus $p$ has a derivation from $\cP$ in degree $d$. 
\end{proof}

\subsubsection{Obstacles for General $c$}
Now that we are changing $c$ as well as $n$, we will write $\cP(n,c)$ for the \textsc{Balanced-CSP} constraints on $n$ vertices with balance $c$.
We want to prove that these constraints admit effective derivations.
What goes wrong if we just try to imitate the proof of \prettyref{thm:bisec-effective}?
If we do so, eventually we arrive at the base case of the induction: $\cP(n-2c,0)$.
The problem is that the linear monomials $x_i$ are in $\gen{\cP(n-2c,0)}$ but it is not obvious how to derive $x_i$ from $\cP(n-2c,0)$. 
In fact, it turns out that derivations of $x_i$ require degree $(n-2c+1)/2$. 

This is not an artifact of our proof strategy, there are essentially two kinds of polynomials in $\gen{\cP(n,c)}$:
Polynomials of degree at most $c$, and polynomials of degree $c+1$ or greater. 
The former have efficient derivations:
\begin{lemma}\label{lem:bcsp-lowdeg}
Let $p \in \gen{\cP(n,c)}$ have degree at most $c$. Then $p$ has a derivation from $\cP(n,c)$ in degree $\deg p$.
\end{lemma}
We delay the proof of this lemma until the next section. 
However, the polynomials of degree $c+1$ or greater actually have no derivations until degree $(n-c+1)/2$, so if $c << n$, then $\cP(n,c)$ is not $k$-effective for any constant $k$.
We will see that this phenomenon is because of the fact that the Pigeonhole Principle requires high degree to prove in the polynomial calculus. 
The negation of the Pigeonhole Principle is the following set of constraints:
\begin{align*}
\nphp(m,n) &= \left\{x_{ij}^2 - x_{ij} | i \in [m], j \in [n]\right\} \\
&\cup \left\{\sum_j x_{ij} - 1 | i \in [m]\right\} \\
&\cup \left\{x_{ij}x_{ik} | i \in [m], j,k \in [n], j \neq k\right\} \\
&\cup \left\{x_{ij}x_{kj} | i,k \in [m], j \in [n], i \neq k\right\}
\end{align*}
$\nphp(m,n)$ asserts the existence of an injective mapping from $[m]$ into $[n]$. If $m > n$, then clearly there is no such mapping, so the set of constraints is unsatisfiable. This implies that $1 \in \gen{\nphp(m,n)}$. However, Razborov proved that any derivation of $1$ from $\nphp(m,n)$ has degree at least $n/2 + 1$ \cite{}.
This allows us to prove the following:
\begin{lemma}\label{lem:bcsp-highdeg-hard}
Let $p = x_1x_2\dots x_c x_{c+1}$. Then $p \in \gen{\cP(n,c)}$, but any derivation of $p$ from $\cP(n,c)$ has degree at least $(n-c+1)/2$. 
\end{lemma}
\begin{proof}
To see that $p \in \gen{\cP(n,c)}$, notice that $V(\cP(n,c))$ are the boolean vectors with exactly $c$ variables equal to $1$.
Because $p$ is a product of $c+1$ variables, at least one of those variables must be equal to $0$, and thus the product is $0$. 
This is essentially a Pigeonhole Principle argument where the pigeons are the $n-c$ zeros, and the holes are the $n-c-1$ variables not appearing in $p$.
More formally, we show how to manipulate any derivation of $p$ from $\cP(n,c)$ to get a derivation of $1$ from $\nphp(n-c,n-c-1)$.

Any derivation of $p$ from $\cP(n,c)$ is a polynomial identity of the following form:
\[x_1x_2\dots x_{c+1} = \lambda \cdot (\sum_i x_i - c) + \sum_i \lambda_i \cdot (x_i^2 - x_i).\]
Now set $x_1 = x_2 = \dots = x_{c+1} = 1$ to get
\[1 = \lambda' \cdot (\sum_{i > c+1} x_i + 1) + \sum_{i > c+1} \lambda_i \cdot (x_i^2 - x_i).\]
We define variables $y_{ij}$ with the intention that $y_{ij} = 1$ if the $i$th variable is the $j$th zero. Thus we replace $x_i \rightarrow 1 - \sum_{j=1}^{n-c} y_{ij}$ and get
\begin{align*}
1 &= \lambda(y) \cdot \left(\sum_{i > c+1} \left(1 - \sum_j y_{ij}\right) + 1\right) + \sum_{i > c+1} \lambda_i(y) \cdot \left( \left(1 - \sum_j y_{ij}\right)^2 - 1 + \sum_j y_{ij}\right) \\
&= \lambda(y) \cdot \left(n-c-1 - \sum_{i> c+1, j} y_{ij} + 1\right) + \sum_{i > c+1} \left(\sum_j y_{ij}^2 - \sum_j y_{ij} + 2\sum_{j\neq j'} y_{ij}y_{ij'}\right) \\
&= \sum_{j=1}^{n-c} -\lambda(y)\cdot\left(\sum_{i > c+1} y_{ij} - 1\right) + \sum_{i > c+1} \left(\sum_j \left(y_{ij}^2 - y_{ij}\right) + 2\sum_{j\neq j'} y_{ij}y_{ij'}\right).
\end{align*}
Note that each term in the last equation contains a constraint in $\nphp(n-c,n-c-1)$. Thus the degree of this derivation must be at least  $(n-c+1)/2$.
\end{proof}

\subsubsection{Effective PC$_>$ Derivations for \textsc{Balanced-CSP}}
\prettyref{lem:bcsp-highdeg-hard} tells us that we cannot hope to prove that $\cP(n,c)$ has effective PC proofs, but we are not soley interested in PC proofs. In particular, because the applications we consider in this thesis are primarily focused on Semidefinite Programming, we have access to the more powerful PC$_>$ proof system. In this system, $\nphp$ is not difficult to refute, and indeed once we allow ourselves PC$_>$ proofs we can show that \textsc{Balanced-CSP} admits effective derivations.
\begin{lemma}\label{lem:highdeg-easy}
Let $p = x_1x_2\dots x_c x_{c+1}$. Then $p$ has a PC$_>$ proof from $\cP(n,c)$ in degree $2(c+1)$ with coefficient size at most $O(1)$. 
\end{lemma}
\begin{proof}
Recall that a PC$_>$ proof consists of two proofs of nonnegativity: one for $p$ and one for $-p$. The first is trivial: every monomial is the multilinearization of itself squared. Thus every monomial has a proof of nonnegativity in twice its degree. For the second, we observe the following identity
\[-x_1x_2\dots x_{c+1} = x_1x_2\dots x_c\left(c - \sum_i x_i\right) + \sum_{i \leq c} -(x_i^2 - x_i) \prod_{j \leq c, j\neq i} x_j + \left(\prod_{i \leq c} x_i\right) \sum_{i > c+1} x_i. \]
The first two terms each have factors in $\cP(n,c)$, and the last term is a sum of monomials with nonnegative coefficients. These monomials all have proofs of nonnegativity, and thus so does $-p$. It is simple to check that these proofs involve coefficients of merely constant size. 
\end{proof}
It remains to prove that the low-degree polynomials in $\cP(n,c)$ have efficient derivations. We will be able to use simple PC derivations for these polynomials. The proof is very similar to the one for \textsc{Bisection}, but we have to do a double induction on $n$ and $c$ since the balance changes in the inductive step. We will take $c \leq n/2$, since the other case is symmetric.
\begin{lemma}\label{lem:lowdeg-easy}
Fix $c \leq n/2$. Let $p \in \gen{\cP(n,c)}$ with $\deg p \leq c$. Then $p$ has a derivation from $\cP(n,c)$ in degree $\deg p$. 
\end{lemma}
\begin{proof}
The proof is by double induction on $n$ and $c$. The base case is the lemma statement for $\cP(n,0)$ for all $n$. In this case $p$ is a constant polynomial, and the only constant polynomial in $\cP(n,0)$ is the zero polynomial, which has the trivial derivation. Now consider the case when $p \in \cP(n,c)$ for $c \leq n/2$. Then following the same argument as in \prettyref{thm:bisec-effective}, we define $\Delta = p - \sigma p = (r_i - r_j)\cdot (x_i - x_j)$, where $r_i$ and $r_j$ do not depend on $x_i$ or $x_j$. Setting $x_i = 1$ and $x_0 = 0$, we again conclude that $(r_i - r_j) \in \gen{\cP(n-2,c-1)}$. Since $c \leq n/2$, clearly $c-1 \leq (n-2)/2$. Also, since $r_i - r_j$ has degree $\deg p - 1$, we still have $\deg (r_i - r_j) \leq c-1$. Thus we can apply the inductive hypothesis to get a derivation for $r_i - r_j$ from $\cP(n-2,c-1)$ in degree $\deg p - 1$. Then \prettyref{lem:bcsp-induct} tells us that $\Delta$ has a derivation from $\cP(n,c)$ in degree $\deg p$, completing the induction. Taken with \prettyref{lem:bcsp-symmetric}, this implies the statement. 
\end{proof}
Together, we now have a proof of the following theorem:
\begin{theorem}
\textsc{Balanced-CSP} on $n$ vertices with balance $c$ admits $(2,O(1))$-effective PC$_>$ derivations. If $c = n/2$, then the derivations can be taken to be $1$-effective PC derivations.
\end{theorem}
\begin{proof}
The theorem is a direct corollary of \prettyref{lem:highdeg-easy}, \prettyref{lem:lowdeg-easy}, and \prettyref{lem:bisec-effective}.
\end{proof}

\section{Problems with Effective Derivations}
We include a theorem here summarizing all the results of this section:
\begin{theorem}
The following sets of constraints admit $k$-effective derivations:
\begin{itemize}
\item
\end{itemize}
The following sets of constraints admit $(k,B)$-effective PC$_>$ derivations:
\begin{itemize}
\item
\end{itemize}
\end{theorem}
